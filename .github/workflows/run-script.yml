name: Run Scraper Script

on:
  workflow_dispatch:
    inputs:
      arg1:
        description: 'Lesson URL to scrape'
        required: true
        type: string

      arg2:
        description: 'Message (not used by parser)'
        required: true
        type: string

      cred:
        description: 'Headers JSON (including cookies)'
        required: true
        type: string

jobs:
  run-script:
    runs-on: ubuntu-latest

    steps:
      - name: ðŸ§¾ Checkout repo
        uses: actions/checkout@v3

      - name: âš¡ Cache node_modules
        uses: actions/cache@v3
        with:
          path: |
            ~/.npm
            node_modules
          key: ${{ runner.os }}-npm-${{ hashFiles('**/package-lock.json') }}

      - name: ðŸ“¦ Install dependencies and manually install Chromium
        run: |
          echo "ðŸ“¦ Running npm install (skip Chromium)..."
          npm install

          echo "â¬‡ï¸ Installing Chromium manually for Puppeteer..."
          PUPPETEER_SKIP_CHROMIUM_DOWNLOAD= npx puppeteer install
        env:
          PUPPETEER_SKIP_CHROMIUM_DOWNLOAD: true

      - name: ðŸ§  Encode message
        id: encode
        run: |
          echo "message64=$(echo "${{ inputs.arg2 }}" | base64 -w 0)" >> $GITHUB_OUTPUT

      - name: ðŸƒ Run scraper script
        env:
          SECURE_COOKIE: "__cf_bp=${{ secrets.CF_BP }}; cf_clearance=${{ secrets.CF_CLEARANCE }}"
        run: |
          echo "ðŸ› ï¸ Writing headers.json"
          echo '${{ inputs.cred }}' > headers.json

          echo "ðŸ”— Running parser for: ${{ inputs.arg1 }}"
          OUTPUT=$(node parser.mjs "${{ inputs.arg1 }}")

          echo "âœ… Scraping complete. Markdown output below:"
          echo "$OUTPUT"
