name: Run Scraper Script
on:
  workflow_dispatch:
    inputs:
      arg1:
        description: 'Lesson URL to scrape'
        required: true
        type: string

      arg2:
        description: 'message'
        required: true
        type: string

jobs:
  run-script:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Cache node_modules
        uses: actions/cache@v3
        with:
          path: |
            ~/.npm
            node_modules
          key: ${{ runner.os }}-npm-${{ hashFiles('**/package-lock.json') }}

      - name: Install dependencies
        run: npm install
        env:
            PUPPETEER_SKIP_CHROMIUM_DOWNLOAD: true

      - name: Run scraper script
        env:
            SECURE_COOKIE: "__cf_bp=${{ secrets.CF_BP }}; cf_clearance=${{ secrets.CF_CLEARANCE }}"
        run: |
          echo "Running with ${{ inputs.arg1 }} $SECURE_COOKIE"
          
          # Save the headers JSON to a temporary file
          echo "${{ secrets.HEADERS_JSON }}" | jq '.' > headers.json

          # Run the script using the JSON file path (not the JSON string)
          node ./my_parser.mjs "${{ inputs.arg1 }}" "${{ inputs.arg2 }}" "$SECURE_COOKIE" headers.json > lesson_output.md 2>&1

      - name: Collect debug files (instead of artifact upload)
        if: always()
        run: |
          mkdir -p output
          cp 403_debug.png output/ || true
          cp 403_debug.html output/ || true
          cp downloaded_data.json output/ || true
          cp lesson_output.md output/ || true
          echo "âœ… Debug files copied to ./output/"
